{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgbm\n",
    "\n",
    "import warnings\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    action=\"ignore\",\n",
    "    module=\"scipy\",\n",
    "    message=\"^.*LAPACK bug 0038.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_data():\n",
    "    # load training data split train_x and train_y\n",
    "    train_pd = pd.read_csv(\"all/train.csv\")\n",
    "\n",
    "    # remove outlier from data analysis\n",
    "    #drop outliers\n",
    "#     query = train_pd[(train_pd['GrLivArea'] > 4000) & (train_pd['SalePrice'] < 200000)]\n",
    "#     train_pd = train_pd.drop(query.index.values)\n",
    "\n",
    "    train_x = train_pd.drop(['SalePrice'], axis=1)\n",
    "    train_x['is_train'] = 1\n",
    "    train_y = np.log1p(train_pd[\"SalePrice\"])\n",
    "    test_pd = pd.read_csv(\"all/test.csv\")\n",
    "    test_pd['is_train'] = 0\n",
    "    \n",
    "    # concate train and test\n",
    "    all_data = pd.concat((train_x, test_pd)).reset_index(drop=True)\n",
    "    all_data = all_data.drop(['Id'], axis=1)\n",
    "    # There are 4 features has more than 80 percent nan value\n",
    "    # drop these columns\n",
    "    all_data = all_data.drop(['Alley', 'PoolQC', 'Fence','MiscFeature'], axis=1)\n",
    "\n",
    "    # drop low variance feature\n",
    "#     all_data = all_data.drop([\"Heating\", 'Exterior2nd', 'Condition2', 'RoofMatl', 'Utilities', 'Street'], axis=1)\n",
    "    \n",
    "    # fill lotfrontage with mean value corespond to overall quality\n",
    "    lot_not_nan = all_data[all_data['LotFrontage'].notna()]\n",
    "    lot_mean_map = dict(lot_not_nan.groupby('OverallQual').mean()['LotFrontage'])\n",
    "    all_data['LotFrontage'] = all_data['LotFrontage'].fillna(all_data['OverallQual'].map(lot_mean_map))\n",
    "    \n",
    "    # MasVnrArea nan means no Masonry veneer area\n",
    "    # just fill with 0\n",
    "    all_data['MasVnrArea'] = all_data['MasVnrArea'].fillna(0)\n",
    "    # BsmtFinSF1, BsmtFinSF2, BsmtUnfSF, TotalBsmtSF with 1 nan only. fill with 0\n",
    "    all_data['BsmtFinSF1'] = all_data['BsmtFinSF1'].fillna(0)\n",
    "    all_data['BsmtFinSF2'] = all_data['BsmtFinSF2'].fillna(0)\n",
    "    all_data['BsmtUnfSF'] = all_data['BsmtUnfSF'].fillna(0)\n",
    "    all_data['TotalBsmtSF'] = all_data['TotalBsmtSF'].fillna(0)\n",
    "    # BsmtFullBath, BsmtHalfBath means basement bathrooms, value can be 0\n",
    "    all_data['BsmtFullBath'] = all_data['BsmtFullBath'].fillna(0)\n",
    "    all_data['BsmtHalfBath'] = all_data['BsmtHalfBath'].fillna(0)\n",
    "    # fill GarageYrBlt with average yearbuilt+3\n",
    "    all_data['GarageYrBlt'] = all_data['GarageYrBlt'].fillna(all_data['YearBuilt'] + 3)\n",
    "    # GarageCars, GarageArea can be 0, fill with 0\n",
    "    all_data['GarageCars'] = all_data['GarageCars'].fillna(0)\n",
    "    all_data['GarageArea'] = all_data['GarageArea'].fillna(0)\n",
    "    # MasVnrType has None value, fill with None\n",
    "    all_data['MasVnrType'] = all_data['MasVnrType'].fillna('None')\n",
    "    # BsmtQual BsmtCond BsmtExposure BsmtFinType1 BsmtFinType2 GarageType GarageFinish GarageQual GarageCond FireplaceQu have NA value, fill with NA\n",
    "    fill_na_col = ['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'FireplaceQu']\n",
    "    all_data[fill_na_col] = all_data[fill_na_col].fillna('NA')\n",
    "    # fill remain nan feature with common value\n",
    "    unfilled = all_data.columns[all_data.isna().any()].tolist()\n",
    "    all_data[unfilled] = all_data[unfilled].fillna(all_data[unfilled].mode().iloc[0])\n",
    "    \n",
    "    # transform some feature to numerical\n",
    "    level_map  = {\n",
    "        'Ex':5,\n",
    "        'Gd':4,\n",
    "        'TA':3,\n",
    "        'Fa':2,\n",
    "        'Po':1,\n",
    "        'NA':0,\n",
    "        'Y':1,\n",
    "        'N':0,\n",
    "        'Reg':3,\n",
    "        'IR1':2,\n",
    "        'IR2':1,\n",
    "        'IR3':0,\n",
    "        \"Unf\" : 1,\n",
    "        \"LwQ\": 2,\n",
    "        \"Rec\" : 3,\n",
    "        \"BLQ\" : 4,\n",
    "        \"ALQ\" : 5,\n",
    "        \"GLQ\" : 6\n",
    "    }\n",
    "    # assign value \n",
    "    all_data['LotShape'] = all_data['LotShape'].map(level_map)\n",
    "    all_data['ExterQual'] = all_data['ExterQual'].map(level_map)\n",
    "    all_data['ExterCond'] = all_data['ExterCond'].map(level_map)\n",
    "    all_data['BsmtQual'] = all_data['BsmtQual'].map(level_map)\n",
    "    all_data['BsmtCond'] = all_data['BsmtCond'].map(level_map)\n",
    "    all_data['BsmtFinType1'] = all_data['BsmtFinType1'].map(level_map)\n",
    "    all_data['BsmtFinType2'] = all_data['BsmtFinType2'].map(level_map)\n",
    "    all_data['HeatingQC'] = all_data['HeatingQC'].map(level_map)\n",
    "    all_data['CentralAir'] = all_data['CentralAir'].map(level_map)\n",
    "    all_data['KitchenQual'] = all_data['KitchenQual'].map(level_map)\n",
    "    all_data['FireplaceQu'] = all_data['FireplaceQu'].map(level_map)\n",
    "    all_data['GarageQual'] = all_data['GarageQual'].map(level_map)\n",
    "    all_data['GarageCond'] = all_data['GarageCond'].map(level_map)\n",
    "    \n",
    "    # build house age feature\n",
    "    house_age = all_data['YrSold'] - all_data['YearBuilt']\n",
    "    all_data['house_age'] = house_age\n",
    "    \n",
    "    all_data['YrBltAndRemod']=all_data['YearBuilt']+all_data['YearRemodAdd']\n",
    "    all_data['TotalSF']=all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']\n",
    "\n",
    "    all_data['Total_sqr_footage'] = (all_data['BsmtFinSF1'] + all_data['BsmtFinSF2'] +\n",
    "                                     all_data['1stFlrSF'] + all_data['2ndFlrSF'])\n",
    "\n",
    "    all_data['Total_Bathrooms'] = (all_data['FullBath'] + (0.5 * all_data['HalfBath']) +\n",
    "                                   all_data['BsmtFullBath'] + (0.5 * all_data['BsmtHalfBath']))\n",
    "\n",
    "    all_data['Total_porch_sf'] = (all_data['OpenPorchSF'] + all_data['3SsnPorch'] +\n",
    "                                  all_data['EnclosedPorch'] + all_data['ScreenPorch'] +\n",
    "                                  all_data['WoodDeckSF'])\n",
    "\n",
    "    # simplified features\n",
    "    all_data['haspool'] = all_data['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    all_data['has2ndfloor'] = all_data['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    all_data['hasgarage'] = all_data['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    all_data['hasbsmt'] = all_data['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    all_data['hasfireplace'] = all_data['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    \n",
    "    # one_hot other features\n",
    "    all_data = pd.get_dummies(all_data)\n",
    "    \n",
    "    train_x = all_data[all_data['is_train'] == 1]\n",
    "    test_x = all_data[all_data['is_train'] == 0]\n",
    "    train_x = train_x.drop(['is_train'], axis=1)\n",
    "    test_x = test_x.drop(['is_train'], axis=1)\n",
    "    \n",
    "    return train_x, train_y, test_x\n",
    "\n",
    "def random_cross_validation(model):\n",
    "    kf = KFold(n_splits=5, random_state=64, shuffle=True).get_n_splits(train_x)\n",
    "    scores = np.sqrt(-cross_val_score(model, train_x, train_y, cv=kf, scoring = 'neg_mean_squared_error'))\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 243) (1460,) (1459, 243)\n"
     ]
    }
   ],
   "source": [
    "# loading data\n",
    "train_x, train_y, test_x = loading_data()\n",
    "print(train_x.shape, train_y.shape, test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building model\n",
    "# lgbm \n",
    "model_lgbm = lgbm.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11,verbosity=0)\n",
    "# xgb\n",
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213,\n",
    "                             random_state =7, nthread = -1)\n",
    "\n",
    "# ridge\n",
    "model_ridge = make_pipeline(RobustScaler(), Ridge(alpha =10, random_state=34))\n",
    "\n",
    "# lasso\n",
    "model_lasso = make_pipeline(RobustScaler(), Lasso(alpha =1, random_state=32 , max_iter = 1e6))\n",
    "\n",
    "# elnet\n",
    "model_ela = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3, max_iter = 1e6))\n",
    "\n",
    "# sgd\n",
    "model_sgd = make_pipeline(RobustScaler(), SGDRegressor(alpha = 1)) \n",
    "\n",
    "# svr\n",
    "model_svr = make_pipeline(RobustScaler(), SVR(C= 20, epsilon= 0.008, gamma=0.0003))\n",
    "\n",
    "\n",
    "# stack\n",
    "kf = KFold(n_splits=5, random_state=64, shuffle=True).get_n_splits(train_x)\n",
    "estimators = [(\"ridge\",model_ridge), (\"lasso\",model_svr), (\"ela\",model_ela)]\n",
    "model_stack = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    cv = kf\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgbm avg score: 0.12023570743586191\n"
     ]
    }
   ],
   "source": [
    "score = random_cross_validation(model_lgbm)\n",
    "print(\"lgbm avg score: \" + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb avg score: 0.12136233265070166\n"
     ]
    }
   ],
   "source": [
    "score = random_cross_validation(model_xgb)\n",
    "print(\"xgb avg score: \" + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge avg score: 0.13840988966240148\n"
     ]
    }
   ],
   "source": [
    "score = random_cross_validation(model_ridge)\n",
    "print(\"ridge avg score: \" + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso avg score: 0.39400141687467155\n"
     ]
    }
   ],
   "source": [
    "score = random_cross_validation(model_lasso)\n",
    "print(\"lasso avg score: \" + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ela avg score: 0.13465033409774954\n"
     ]
    }
   ],
   "source": [
    "score = random_cross_validation(model_ela)\n",
    "print(\"ela avg score: \" + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD avg score: 1016616197197361.2\n"
     ]
    }
   ],
   "source": [
    "score = random_cross_validation(model_sgd)\n",
    "print(\"SGD avg score: \" + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR avg score: 0.18216422045126318\n"
     ]
    }
   ],
   "source": [
    "score = random_cross_validation(model_svr)\n",
    "print(\"SVR avg score: \" + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stack avg score: 0.13502409344411337\n"
     ]
    }
   ],
   "source": [
    "score = random_cross_validation(model_stack)\n",
    "print(\"stack avg score: \" + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack avg score: 0.13610616260087877"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submission section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb.fit(train_x, train_y)\n",
    "model_lgbm.fit(train_x, train_y)\n",
    "model_stack.fit(train_x, train_y)\n",
    "y_pred_xgb = model_xgb.predict(test_x)\n",
    "y_pred_lgbm = model_lgbm.predict(test_x)\n",
    "y_pred_stack = model_stack.predict(test_x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1459,) (1459,)\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_xgb.shape, y_pred_lgbm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1459,)\n"
     ]
    }
   ],
   "source": [
    "# y_pred = 0.4 * np.expm1(y_pred_xgb) + 0.6 *np.expm1(y_pred_lgbm) 0.11963  top 7%\n",
    "# y_pred = 0.2 * np.expm1(y_pred_xgb) + 0.7 *np.expm1(y_pred_lgbm) + 0.1 * np.expm1(y_pred_stack) 0.11907 \n",
    "# y_pred = 0.15 * np.expm1(y_pred_xgb) + 0.7 *np.expm1(y_pred_lgbm) + 0.05 * np.expm1(y_pred_stack) 0.11904\n",
    "# y_pred = 0.2 * np.expm1(y_pred_xgb) + 0.5 *np.expm1(y_pred_lgbm) + 0.3 * np.expm1(y_pred_stack) 0.120...\n",
    "# y_pred = 0.15 * np.expm1(y_pred_xgb) + 0.7 *np.expm1(y_pred_lgbm) + 0.15 * np.expm1(y_pred_stack) 0.118!!!\n",
    "y_pred = 0.15 * np.expm1(y_pred_xgb) + 0.7 *np.expm1(y_pred_lgbm) + 0.15 * np.expm1(y_pred_stack)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1459,)\n"
     ]
    }
   ],
   "source": [
    "model_lgbm.fit(train_x, train_y)\n",
    "y_pred = model_lgbm.predict(test_x)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>124358.533544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>163599.278001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>184042.689237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>197572.749890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>194572.282451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id      SalePrice\n",
       "0  1461  124358.533544\n",
       "1  1462  163599.278001\n",
       "2  1463  184042.689237\n",
       "3  1464  197572.749890\n",
       "4  1465  194572.282451"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pd = pd.read_csv('all/test.csv')\n",
    "sub = pd.concat([test_pd['Id'],pd.DataFrame(y_pred)],axis=1)\n",
    "sub.columns=['Id','SalePrice']\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
